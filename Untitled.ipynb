{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0f00429289fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaleFactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mleft_eye\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleye\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mright_eye\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mreye\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import time\n",
    "\n",
    "\n",
    "mixer.init()\n",
    "sound = mixer.Sound('alarm.wav')\n",
    "\n",
    "face = cv2.CascadeClassifier('haar cascade files\\haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier('haar cascade files\\haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier('haar cascade files\\haarcascade_righteye_2splits.xml')\n",
    "\n",
    "\n",
    "\n",
    "lbl=['Close','Open']\n",
    "\n",
    "model = load_model('models/cnncat2.h5')\n",
    "path = os.getcwd()\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "count=0\n",
    "score=0\n",
    "thicc=2\n",
    "rpred=[99]\n",
    "lpred=[99]\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    height,width = frame.shape[:2] \n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "    left_eye = leye.detectMultiScale(gray)\n",
    "    right_eye =  reye.detectMultiScale(gray)\n",
    "\n",
    "    cv2.rectangle(frame, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 1 )\n",
    "\n",
    "    for (x,y,w,h) in right_eye:\n",
    "        r_eye=frame[y:y+h,x:x+w]\n",
    "        count=count+1\n",
    "        r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "        r_eye = cv2.resize(r_eye,(24,24))\n",
    "        r_eye= r_eye/255\n",
    "        r_eye=  r_eye.reshape(24,24,-1)\n",
    "        r_eye = np.expand_dims(r_eye,axis=0)\n",
    "        rpred = model.predict_classes(r_eye)\n",
    "        if(rpred[0]==1):\n",
    "            lbl='Open' \n",
    "        if(rpred[0]==0):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "\n",
    "    for (x,y,w,h) in left_eye:\n",
    "        l_eye=frame[y:y+h,x:x+w]\n",
    "        count=count+1\n",
    "        l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)  \n",
    "        l_eye = cv2.resize(l_eye,(24,24))\n",
    "        l_eye= l_eye/255\n",
    "        l_eye=l_eye.reshape(24,24,-1)\n",
    "        l_eye = np.expand_dims(l_eye,axis=0)\n",
    "        lpred = model.predict_classes(l_eye)\n",
    "        if(lpred[0]==1):\n",
    "            lbl='Open'   \n",
    "        if(lpred[0]==0):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "\n",
    "    if(rpred[0]==0 and lpred[0]==0):\n",
    "        score=score+1\n",
    "        cv2.putText(frame,\"Closed\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    # if(rpred[0]==1 or lpred[0]==1):\n",
    "    else:\n",
    "        score=score-1\n",
    "        cv2.putText(frame,\"Open\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    \n",
    "        \n",
    "    if(score<0):\n",
    "        score=0   \n",
    "    cv2.putText(frame,'Score:'+str(score),(100,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    if(score>15):\n",
    "        #person is feeling sleepy so we beep the alarm\n",
    "        cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n",
    "        try:\n",
    "            sound.play()\n",
    "            \n",
    "        except:  # isplaying = False\n",
    "            pass\n",
    "        if(thicc<16):\n",
    "            thicc= thicc+2\n",
    "        else:\n",
    "            thicc=thicc-2\n",
    "            if(thicc<2):\n",
    "                thicc=2\n",
    "        cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thicc) \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open model/shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b4c2d4eff633>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mlandmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model/shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mface_recognition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open model/shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import datetime\n",
    "\n",
    "#start web cam\n",
    "webcam = VideoStream(src=0).start()\n",
    "time.sleep(1.0)\n",
    "\n",
    "landmarks = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\n",
    "face_recognition = dlib.get_frontal_face_detector()\n",
    "\n",
    "sleep_count = 0\n",
    "max_sleep_count = 30\n",
    "\n",
    "normal = False\n",
    "normal_count = 0.0\n",
    "normal_eye_ratio = 0\n",
    "\n",
    "frame = webcam.read()\n",
    "frame = imutils.resize(frame, width=450)\n",
    "img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    " # insert information text to video frame\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "input_frame = img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "CurrentTime= now.strftime(\"%Y-%m-%d %H:%M:%d\")\n",
    "cv2.putText(frame, \"Sleep Detector: \" + str(CurrentTime), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0xFF, 0xFF, 0xFF0), 2)\n",
    "def eye_ratio(eye):\n",
    "    avg_height = (abs(eye[1][1]-eye[5][1])+abs(eye[2][1]-eye[4][1]))/2\n",
    "    width = abs(eye[0][0]-eye[3][0])\n",
    "\n",
    "    return avg_height/width\n",
    "while True:\n",
    "    #get the image corresponding to a frame\n",
    "    frame = webcam.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_recognition(img, 0)\n",
    "        \n",
    "    if(not(normal) and normal_count<47):\n",
    "\n",
    " # insert information text to video frame\n",
    "    \n",
    "        cv2.rectangle(input_frame, (1, 50), (50, 80), (180, 132, 109), -1)\n",
    "        cv2.putText(\n",
    "            input_frame,\n",
    "            'ATTENTION PLEASE - Your activities are being logged',\n",
    "            (60, 70),\n",
    "            font,\n",
    "            0.5,\n",
    "            (0xFF, 0xFF, 0xFF),\n",
    "            1,\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            )\n",
    "\n",
    " #       cv2.putText(frame, \"FOCUS YOUR NORMAL EYES\", (100, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "    for face in faces:\n",
    "        #get the landmark data for the face as numpy array\n",
    "        face_data = face_utils.shape_to_np(landmarks(img,face))\n",
    "        \n",
    "        #left eye positions are from 36th index to 41st index\n",
    "        #right eye positions are from 42th index to 47st index\n",
    "        \n",
    "        #get eye data and show in the frame \n",
    "        left_eye = face_data[36:42]\n",
    "        right_eye = face_data[42:48]\n",
    "        \n",
    "        leftEyeHull = cv2.convexHull(left_eye)\n",
    "        rightEyeHull = cv2.convexHull(right_eye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        \n",
    "        eye_avg_ratio = eye_ratio(left_eye)+eye_ratio(right_eye)/2.0\n",
    "        #print(eye_avg_ratio)\n",
    "        if(not(normal)):\n",
    "            if(normal_count<50):\n",
    "               normal_eye_ratio = normal_eye_ratio+eye_avg_ratio\n",
    "            else:\n",
    "                normal_eye_ratio = normal_eye_ratio/normal_count\n",
    "                normal = True\n",
    "                cv2.putText(frame, \"Sleep Detector: \" + str(CurrentTime), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0xFF, 0xFF, 0xFF0), 2)\n",
    " #               cv2.putText(frame, \"LETS START!\", (140, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (150, 0, 255), 3)\n",
    "                print(normal_eye_ratio)\n",
    "                \n",
    "        normal_count=normal_count+1\n",
    "            \n",
    "    else:\n",
    "            #print(normal_eye_ratio-eye_avg_ratio)\n",
    "            if(normal_eye_ratio-eye_avg_ratio>0.05):\n",
    "                sleep_count = sleep_count+1\n",
    "                GPA=sleep_count/30\n",
    "                \n",
    "                if(sleep_count>max_sleep_count):\n",
    "                     now = datetime.datetime.now()\n",
    "                     CurrentTime= now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                     cv2.putText(frame, \"Sleep Detector: \" + str(CurrentTime), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0xFF, 0xFF, 0xFF0), 2)\n",
    "                     cv2.putText(frame, \"Sleeping time (seconds):\" + str(\"%6.0f \" % GPA), (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0xFF, 0xFF, 0xFF0), 2)\n",
    "                if ((GPA > 2) and (GPA < 5)):\n",
    "                     cv2.putText(frame, \"Alert! You should take a rest\", (10, 230), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                print(\"Sleeping log - Time: \" + str(CurrentTime) + \" Duration: \" + str(\"%6.0f\" % GPA))\n",
    "            else:\n",
    "                sleep_count = 0\n",
    "        \n",
    "    #show web cam frame \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if(normal_count==51):\n",
    "        cv2.waitKey(1000)\n",
    "        normal_count = 0\n",
    "    else:\n",
    "        wait = cv2.waitKey(1)\n",
    "        if wait==ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            webcam.stop()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
